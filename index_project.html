<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=yes, initial-scale=1, maximum-scale=1">
    <title>Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.1"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0"></script>
  </head>
  <body>
<!--      <img src="cat2.jpg">-->
<!--      <script>-->
<!--        // javascriptÏùò Ìï®ÏàòÏôÄ ÏΩúÎ∞± : https://opentutorials.org/course/743/6508-->
<!--        img = document.querySelector('img');-->
<!--        mobilenet.load().then(model => {-->
<!--          model.classify(img).then(predictions => {-->
<!--            alert(predictions[0].className + ': ' + predictions[0].probability);-->
<!--            console.log(predictions);-->
<!--          });-->
<!--        });-->

<!--        // ÏúÑ ÏΩîÎìúÏôÄ ÎèôÏùº-->
<!--        //-->
<!--        // img = document.querySelector('img');-->
<!--        // function classifyCallback(predictions) {-->
<!--        //   alert(predictions[0].className + ': ' + predictions[0].probability);-->
<!--        //   console.log(predictions);-->
<!--        // }-->
<!--        // function loadCallback(model) {-->
<!--        //   model.classify(img).then(classifyCallback);-->
<!--        // }-->
<!--        // mobilenet.load().then(loadCallback);-->
<!--      </script>-->
<!--      <br> <input type='file' accept='image/*'>-->
<!--      <img>-->
<!--      <script>-->
<!--        input = document.querySelector('input');-->
<!--        img = document.querySelector('img');-->
<!--        input.onchange = function(){-->
<!--          img.src = URL.createObjectURL(input.files[0]);-->
<!--        };-->
<!--      </script>-->

      <video playsinline autoplay></video>
      <button>Take snapshot</button>
      <canvas></canvas>
      <span></span>
      <script>
        video = document.querySelector('video');
        canvas = document.querySelector('canvas');
        canvas.width = 48;
        canvas.height = 48;
        canvas.style.filter = 'graycscale(1)';
        video.style.transform = 'scaleX(-1)';

        span = document.querySelector('span');
        span.style.fontSize = '48px';

        const LABELS = {
            0: 'ü§¨', // angry
            1: 'ü§¢', // disgust
            2: 'üò±', // fear
            3: 'üòÑ', // happy
            4: 'üò¢', // sad
            5: 'üò≤', // surprise
            6: 'üòê' // neutral
        }

        async function predict(){
            const model = await tf.loadLayersModel('./model/model_8/model.json');

            image = tf.browser.fromPixels(canvas);
            console.log(image);
            image = image.toFloat().mean(2).mul(1/255.0).reshape([-1, 48, 48, 1]);
            logits = model.predict(image);
            const results = await logits.softmax().data();
            i = results.indexOf(Math.max(...results));

            image.dispose();
            logits.dispose();
            console.log(results);

            span.innerHTML = LABELS[i];
        }

        button = document.querySelector('button');
        button.onclick = function(){
            w = video.videoWidth;
            h = video.videoHeight;
            s = Math.min(w, h);
            sx = (w - s)/2;
            sy = (h - s)/2;

            canvas.getContext('2d').drawImage(video, sx=sx, sy=sy, swidth=s, sheight=s,
                x=0, y=0, width=48, height=48);

            span.innerHTML = '‚åõ';
            predict();
        };



        constraints = {
            audio: false,
            video: true
        };

        function handleSuccess(stream){
            video.srcObject = stream;
        }

        function handleError(error){
            alert('navigator.mediaDevices.getUserMedia error: ' +
            error.message + error.name)
        }

        navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess).catch(handleError)
      </script>
  </body>
</html>